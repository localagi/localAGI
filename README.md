## ðŸ§® localAGI ðŸ§®
Thats me. Building AGI on local hardware.

*You want to run your own inferences with ease? Good you are awake.*


Building contaners for effectively running a local artificial general intelligence.

## Motivation

Initially started my work for deployments of [josh-XT/AGiXT](https://github.com/Josh-XT/AGiXT)

Having reproducable software environments to spin up services on demand for testing and sky-netting.
Setup and streamline docker containers for quick and user friendly usage.

CUDA enabled. Matrix builds. Multiarch builds. For everyone.

## Sharing is caring

With strong expertise in `docker` and `github workflows` I want to bring all the AI-related projects online.

Working on [AI-dedicated Workflows](https://github.com/localagi/ai-dedicated-workflows) to share best practices over several repositories and projects.

## State of work

The following projects on my namespace are built using the **AI pipeline**.
My maintenance is focussed on build stabilty and availability of service containers.

### AI-pipeline-built services running inference
| Service                                                      | Model-types     | Model-quantisations | API-compatibility | Release              | Original Repo |
---------------------------------------------|-----------------|---------------------|-------------------|----------------------|---------------|
| [FastChat](https://github.com/localagi/FastChat-docker)       | e.g. Vicuna, T5 | T5, HF              | OpenAI            | :heavy_check_mark:   | https://github.com/lm-sys/FastChat |
| [oobabooga](https://github.com/localagi/oobabooga-docker)     | LLama           | HF, GGML, GPTQ      | oobabooga         | (:heavy_check_mark:) | https://github.com/oobabooga/text-generation-webui |
| [llama-cpp](https://github.com/localagi/llama-cpp-server)     | LLama           | HF, GGML, GPTQ      | ?                 | WIP | https://github.com/abetlen/llama-cpp-python |
| gpt4all | | | | WIP |  |
| gpt4free | | | | WIP |  |
| [stablediffusion2](localagi/stablediffusion2-docker) |        |                     |                   |                     WIP  | |

### AI-pipeline-built services using inference services
| Service                                                       |  Release              | Original Repo |
|---------------------------------------------------------------|-----------------------|---------------|
| [gpt-code-ui](https://github.com/localagi/gpt-code-ui-docker) | (:heavy_check_mark:)  | https://github.com/ricklamers/gpt-code-ui |
| [AGiXT](https://github.com/localagi/agent-llm)                | (:heavy_check_mark:)  | https://github.com/josh-xt/AGiXT |



## Requests
Any? Contact me (curently on AGiXT-Discord)



<!--
**localagi/localAGI** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- 
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
